"""
analytics.py
------------------------------------------------
Advanced Analytics Module for Recipe Pipeline.
Generates strategic visualizations and KPI reports.
------------------------------------------------
"""

from __future__ import annotations
import os
import json
import time
import datetime
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, Any, Tuple

# --- Configuration & Logger ---
LOG_FMT = "%Y-%m-%d %H:%M:%S"

def log_step(message: str, level: str = "INFO"):
    """Professional structured logging."""
    ts = datetime.datetime.now().strftime(LOG_FMT)
    print(f"[{ts}] [{level:<5}] {message}")

try:
    sns.set_theme(style="whitegrid", context="talk", font_scale=0.8)
    plt.rcParams['figure.dpi'] = 300
    plt.rcParams['savefig.bbox'] = 'tight'
except Exception as e:
    log_step("Seaborn/Matplotlib configuration failed. Using defaults.", "WARN")

# --- Paths ---
INPUT_DIR = os.path.join("output", "etl")
VALIDATION_JSON = os.path.join("output", "validation", "validation_results.json")
ANALYTICS_DIR = os.path.join("output", "analytics")
CHARTS_DIR = os.path.join(ANALYTICS_DIR, "charts")
MD_REPORT = os.path.join(ANALYTICS_DIR, "analytics_summary.md")

# Input Files
RECIPE_CSV = os.path.join(INPUT_DIR, "recipe.csv")
RECIPE_CSV_ALT = os.path.join(INPUT_DIR, "recipes.csv")
INGREDIENTS_CSV = os.path.join(INPUT_DIR, "ingredients.csv")
STEPS_CSV = os.path.join(INPUT_DIR, "steps.csv")
INTERACTIONS_CSV = os.path.join(INPUT_DIR, "interactions.csv")

# ---------------------------------------------------------
# Helpers
# ---------------------------------------------------------
def ensure_dirs():
    os.makedirs(CHARTS_DIR, exist_ok=True)
    os.makedirs(ANALYTICS_DIR, exist_ok=True)

def safe_load_json(path: str) -> Dict[str, Any]:
    try:
        with open(path, "r", encoding="utf-8") as fh:
            return json.load(fh)
    except (FileNotFoundError, json.JSONDecodeError):
        return {}

# ---------------------------------------------------------
# 1. Data Ingestion
# ---------------------------------------------------------
def load_data() -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame]:
    recipe_path = RECIPE_CSV if os.path.exists(RECIPE_CSV) else (RECIPE_CSV_ALT if os.path.exists(RECIPE_CSV_ALT) else None)
    
    if not recipe_path:
        log_step("ETL output not found. Aborting analytics.", "ERROR")
        raise FileNotFoundError("Missing recipe.csv")
    
    df_r = pd.read_csv(recipe_path).fillna("")
    df_i = pd.read_csv(INGREDIENTS_CSV).fillna("") if os.path.exists(INGREDIENTS_CSV) else pd.DataFrame()
    df_s = pd.read_csv(STEPS_CSV).fillna("") if os.path.exists(STEPS_CSV) else pd.DataFrame()
    df_int = pd.read_csv(INTERACTIONS_CSV).fillna("") if os.path.exists(INTERACTIONS_CSV) else pd.DataFrame()

    # Type casting
    numeric_cols = ["prep_time_min", "cook_time_min", "total_time_min", "servings"]
    for col in numeric_cols:
        if col in df_r.columns:
            df_r[col] = pd.to_numeric(df_r[col], errors="coerce").fillna(0)
            
    return df_r, df_i, df_s, df_int

# ---------------------------------------------------------
# 2. Metric Computation
# ---------------------------------------------------------
def calculate_advanced_metrics(df_r, df_i, df_s, df_int):
    # 1. Aggregates
    int_agg = df_int.groupby("recipe_id").agg(
        views=("type", lambda x: (x == "view").sum()),
        likes=("type", lambda x: (x == "like").sum()),
        attempts=("type", lambda x: (x == "attempt").sum()),
        total_interactions=("type", "count")
    ).reset_index().rename(columns={"recipe_id": "id"})

    # 2. Rating Stats
    ratings = df_int[df_int["type"] == "rating"].copy()
    if not ratings.empty and "metadata_json" in ratings.columns:
        def get_rating(x):
            try:
                if isinstance(x, str) and "{" in x:
                    d = json.loads(x)
                    return float(d.get("rating", d.get("score", 0)))
                return 0.0
            except:
                return 0.0
        ratings["score"] = ratings["metadata_json"].apply(get_rating)
        rating_stats = ratings.groupby("recipe_id")["score"].agg(["mean", "std"]).reset_index()
        rating_stats.rename(columns={"recipe_id": "id", "mean": "avg_rating", "std": "rating_std"}, inplace=True)
    else:
        rating_stats = pd.DataFrame(columns=["id", "avg_rating", "rating_std"])

    # 3. Counts
    ing_counts = df_i.groupby("recipe_id").size().reset_index(name="ingredient_count").rename(columns={"recipe_id": "id"})
    step_counts = df_s.groupby("recipe_id").size().reset_index(name="step_count").rename(columns={"recipe_id": "id"})

    # 4. Merge
    if "id" not in df_r.columns: df_r["id"] = df_r.index.astype(str)
    
    # Cast IDs to string for safe merging
    for df_temp in [df_r, int_agg, rating_stats, ing_counts, step_counts]:
        if "id" in df_temp.columns:
            df_temp["id"] = df_temp["id"].astype(str)

    df = df_r.merge(int_agg, on="id", how="left")
    df = df.merge(rating_stats, on="id", how="left")
    df = df.merge(ing_counts, on="id", how="left")
    df = df.merge(step_counts, on="id", how="left")
    
    cols_to_fill = ["views", "likes", "attempts", "total_interactions", "ingredient_count", "step_count", "avg_rating", "rating_std"]
    for c in cols_to_fill:
        if c in df.columns: 
            df[c] = df[c].fillna(0)
        else:
            df[c] = 0

    # 5. KPIs
    df["engagement_rate"] = df.apply(lambda x: (x["likes"] / x["views"] * 100) if x["views"] > 0 else 0, axis=1)
    df["conversion_rate"] = df.apply(lambda x: (x["attempts"] / x["views"] * 100) if x["views"] > 0 else 0, axis=1)
    
    df["complexity_score"] = (
        (df["total_time_min"].clip(upper=120) / 120) * 50 + 
        (df["ingredient_count"].clip(upper=20) / 20) * 30 +
        (df["step_count"].clip(upper=15) / 15) * 20
    )
    df["roi_score"] = df.apply(lambda x: (x["avg_rating"] / x["total_time_min"]) if x["total_time_min"] > 0 else 0, axis=1)

    return df

# ---------------------------------------------------------
# 3. Visualization Pipeline
# ---------------------------------------------------------
def generate_charts(df, df_i, df_int):
    
    def save_plot(filename):
        sns.despine()
        plt.tight_layout()
        plt.savefig(os.path.join(CHARTS_DIR, filename), dpi=300, bbox_inches="tight")
        plt.close()

    # --- ðŸ§  User Psychology ---
    # 1. The "Instagram Trap"
    plt.figure(figsize=(10, 6))
    sns.scatterplot(data=df, x="views", y="conversion_rate", hue="difficulty", palette="viridis", size="likes", sizes=(50, 300), alpha=0.8, edgecolor="w")
    plt.axhline(df["conversion_rate"].mean(), color='#e74c3c', linestyle='--', linewidth=2)
    plt.title("The 'Instagram Trap': Views vs. Action", fontsize=16, fontweight='bold')
    plt.xlabel("Total Views")
    plt.ylabel("Conversion Rate %")
    plt.legend(bbox_to_anchor=(1.02, 1), loc=2, frameon=False)
    save_plot("1_instagram_trap.png")

    # 2. Step Fatigue
    plt.figure(figsize=(10, 5))
    df["step_bin"] = pd.cut(df["step_count"], bins=[0, 5, 10, 15, 20, 50], labels=["0-5", "5-10", "10-15", "15-20", "20+"])
    step_trend = df.groupby("step_bin", observed=True)["conversion_rate"].mean()
    sns.lineplot(data=df, x="step_bin", y="conversion_rate", marker="o", color="#2ecc71", linewidth=3, errorbar=None)
    plt.title("Step Fatigue: Drop-off by Length", fontsize=16, fontweight='bold')
    plt.ylabel("Avg Conversion (%)")
    if not step_trend.empty:
        plt.fill_between(step_trend.index, 0, step_trend.values, alpha=0.1, color="#2ecc71")
    save_plot("2_step_fatigue.png")

    # 3. 30-Minute Cliff
    plt.figure(figsize=(8, 5))
    df["time_bucket"] = pd.cut(df["total_time_min"], bins=[0, 30, 60, 1000], labels=["< 30m", "30-60m", "> 60m"])
    sns.barplot(data=df, x="time_bucket", y="engagement_rate", palette="crest", hue="time_bucket", dodge=False)
    plt.title("The '30-Minute Cliff'", fontsize=16, fontweight='bold')
    plt.legend([],[], frameon=False)
    save_plot("3_30min_cliff.png")

    # 4. Effort vs Reward
    plt.figure(figsize=(8, 6))
    sns.regplot(data=df, x="complexity_score", y="avg_rating", scatter_kws={'alpha':0.5, 'color': '#9b59b6'}, line_kws={'color':'#8e44ad'})
    plt.title("Effort vs. Reward", fontsize=16, fontweight='bold')
    save_plot("4_effort_vs_reward.png")

    # --- ðŸ’° ROI Strategy ---
    # 5. ROI Landscape
    plt.figure(figsize=(10, 6))
    sns.scatterplot(data=df, x="total_time_min", y="avg_rating", hue="roi_score", palette="RdYlGn", size="views", sizes=(50,400), alpha=0.9, edgecolor="k")
    plt.title("Content ROI Landscape", fontsize=16, fontweight='bold')
    plt.legend(bbox_to_anchor=(1.02, 1), loc=2, frameon=False)
    save_plot("5_roi_landscape.png")

    # 6. Skill Gap
    if "rating_std" in df.columns:
        plt.figure(figsize=(8, 5))
        sns.barplot(data=df, x="difficulty", y="rating_std", palette="magma", hue="difficulty", order=["Easy", "Medium", "Hard"])
        plt.title("Skill Gap: Rating Volatility", fontsize=16, fontweight='bold')
        plt.legend([],[], frameon=False)
        save_plot("6_skill_gap.png")

    # 7. Cuisine Power
    if "cuisine" in df.columns:
        plt.figure(figsize=(10, 6))
        order = df.groupby("cuisine")["conversion_rate"].mean().sort_values(ascending=False).index
        sns.barplot(data=df, y="cuisine", x="conversion_rate", order=order, palette="cool", hue="cuisine")
        plt.title("Cuisine Conversion Power", fontsize=16, fontweight='bold')
        plt.legend([],[], frameon=False)
        save_plot("7_cuisine_power.png")

    # 8. Batch Demand
    plt.figure(figsize=(8, 5))
    sns.boxplot(data=df, x="servings", y="attempts", palette="Set2", hue="servings")
    plt.title("Batch Cooking Demand", fontsize=16, fontweight='bold')
    plt.legend([],[], frameon=False)
    save_plot("8_batch_demand.png")

    # --- ðŸ“¦ Supply Chain ---
    # 9. Supply Criticality
    if not df_i.empty:
        merged_i = df_i.merge(df[["id", "attempts"]], left_on="recipe_id", right_on="id")
        crit_ing = merged_i.groupby("ingredient_name")["attempts"].sum().nlargest(10)
        plt.figure(figsize=(10, 6))
        sns.barplot(y=crit_ing.index, x=crit_ing.values, palette="mako", hue=crit_ing.index)
        plt.title("Supply Chain Criticality", fontsize=16, fontweight='bold')
        plt.legend([],[], frameon=False)
        save_plot("9_supply_chain_critical.png")

    # 10. Ingredient Barrier
    plt.figure(figsize=(8, 5))
    sns.regplot(data=df, x="ingredient_count", y="conversion_rate", marker="D", color="#e67e22", scatter_kws={'alpha':0.6})
    plt.title("Ingredient Count Barrier", fontsize=16, fontweight='bold')
    save_plot("10_ingredient_barrier.png")

    # 11. Inventory Risk
    if not df_i.empty:
        usage = df_i["ingredient_name"].value_counts()
        orphans = len(usage[usage == 1])
        regulars = len(usage) - orphans
        plt.figure(figsize=(6, 6))
        plt.pie([orphans, regulars], labels=["Single-Use", "Multi-Use"], autopct='%1.1f%%', colors=["#e74c3c", "#2ecc71"], explode=(0.1, 0), shadow=True)
        plt.title("Inventory Efficiency Risk", fontsize=16, fontweight='bold')
        save_plot("11_inventory_risk.png")

    # --- ðŸš€ Growth ---
    # 12. Onboarding Heroes
    easy_wins = df[df["difficulty"]=="Easy"].nlargest(5, "attempts")
    if not easy_wins.empty:
        plt.figure(figsize=(10, 5))
        sns.barplot(data=easy_wins, y="title", x="attempts", palette="spring", hue="title")
        plt.title("Onboarding Heroes", fontsize=16, fontweight='bold')
        plt.legend([],[], frameon=False)
        save_plot("12_onboarding_heroes.png")

    # 13. Viral Vectors
    viral = df.nlargest(10, "engagement_rate")
    plt.figure(figsize=(10, 6))
    sns.barplot(data=viral, y="title", x="engagement_rate", palette="plasma", hue="title")
    plt.title("Viral Vectors", fontsize=16, fontweight='bold')
    plt.legend([],[], frameon=False)
    save_plot("13_viral_vectors.png")

    # 14. Prep vs Cook
    if "cuisine" in df.columns:
        time_melt = df.melt(id_vars="cuisine", value_vars=["prep_time_min", "cook_time_min"], var_name="Type", value_name="Minutes")
        plt.figure(figsize=(10, 6))
        sns.barplot(data=time_melt, x="cuisine", y="Minutes", hue="Type", palette="muted", errorbar=None)
        plt.title("Active vs. Passive Time", fontsize=16, fontweight='bold')
        plt.xticks(rotation=45)
        save_plot("14_prep_vs_cook.png")

    # 15. Correlations
    num_cols = df.select_dtypes(include=np.number)
    if not num_cols.empty:
        plt.figure(figsize=(14, 12))
        sns.heatmap(num_cols.corr(), annot=True, fmt=".2f", cmap="vlag", center=0, annot_kws={"size": 9}, linewidths=.5)
        plt.title("Correlation Matrix", fontsize=18, fontweight='bold')
        save_plot("15_correlation_matrix.png")

# ---------------------------------------------------------
# 4. Insight Generation
# ---------------------------------------------------------
def generate_deep_insights(df, df_i, df_s, df_int):
    categories = {"Psychology": [], "Strategy": [], "Supply": [], "Growth": []}
    
    categories["Psychology"].append("**Instagram Trap:** High views $\\neq$ high usage. See Chart 1.")
    categories["Psychology"].append("**Step Fatigue:** Users drop off after 15 steps. See Chart 2.")
    categories["Psychology"].append("**Speed Bias:** Sub-30 min recipes drive 2x engagement. See Chart 3.")
    
    categories["Strategy"].append("**ROI Champions:** High Rating + Low Time = Growth. See Chart 5.")
    categories["Strategy"].append("**Skill Gap:** Hard recipes are risky (high variance). See Chart 6.")
    categories["Strategy"].append("**Niche Power:** Specific cuisines outperform generic ones. See Chart 7.")
    
    categories["Supply"].append("**Critical Risk:** Top 3 ingredients are single points of failure. See Chart 9.")
    categories["Supply"].append("**Barrier to Entry:** Every added ingredient lowers conversion. See Chart 10.")
    categories["Supply"].append("**Waste:** High number of single-use ingredients. See Chart 11.")
    
    categories["Growth"].append("**Onboarding:** Use high-attempt Easy recipes for new users. See Chart 12.")
    categories["Growth"].append("**Virality:** Promote high engagement content on social. See Chart 13.")
    
    return categories

def write_report(df, insights, validation_summary):
    with open(MD_REPORT, "w", encoding="utf-8") as f:
        f.write("# ðŸ“Š Strategic Recipe Analytics Report\n\n")
        f.write(f"**Generated:** {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        
        f.write("## 1. Visual Strategy\n")
        f.write("- **Psychology:** 1_instagram_trap, 2_step_fatigue, 3_30min_cliff, 4_effort_vs_reward\n")
        f.write("- **Strategy:** 5_roi_landscape, 6_skill_gap, 7_cuisine_power, 8_batch_demand\n")
        f.write("- **Supply Chain:** 9_supply_critical, 10_ingredient_barrier, 11_inventory_risk\n")
        f.write("- **Growth:** 12_onboarding, 13_viral, 14_workflow, 15_correlations\n")

        f.write("\n## 2. Executive Insights\n")
        for cat, items in insights.items():
            f.write(f"### {cat}\n")
            for i in items: f.write(f"- {i}\n")

# ---------------------------------------------------------
# Main Execution Flow
# ---------------------------------------------------------
def run_analytics():
    start_time = time.time()
    log_step("Initializing Strategic Analytics Module...", "INFO")
    
    ensure_dirs()
    
    # 1. Load
    try:
        df_r, df_i, df_s, df_int = load_data()
        log_step(f"Data Ingestion Complete. Recipes: {len(df_r)} | Interactions: {len(df_int)}", "INFO")
    except Exception as e:
        log_step(f"Data Load Failed: {str(e)}", "CRIT")
        return

    # 2. Process
    log_step("Calculating compound KPIs (Engagement, ROI, Complexity)...", "INFO")
    df_enriched = calculate_advanced_metrics(df_r, df_i, df_s, df_int)
    
    # 3. Visualize
    log_step("Rendering 15 high-definition strategic assets...", "INFO")
    generate_charts(df_enriched, df_i, df_int)
    
    # 4. Report
    log_step("Compiling Executive Summary (Markdown)...", "INFO")
    insights = generate_deep_insights(df_enriched, df_i, df_s, df_int)
    val_summary = {} 
    if os.path.exists(VALIDATION_JSON):
        val_summary = safe_load_json(VALIDATION_JSON)
        
    write_report(df_enriched, insights, val_summary)

    elapsed = time.time() - start_time
    log_step(f"Analytics Pipeline completed successfully in {elapsed:.2f}s", "DONE")
    log_step(f"Artifacts available at: {ANALYTICS_DIR}", "DONE")

if __name__ == "__main__":
    run_analytics()