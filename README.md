# Firebase Recipe Analytics Pipeline

![Python](https://img.shields.io/badge/Python-3.9%2B-blue?logo=python)
![Firebase](https://img.shields.io/badge/Firebase-Firestore-orange?logo=firebase)
![ETL](https://img.shields.io/badge/Pipeline-ETL-green)
![Status](https://img.shields.io/badge/Status-Production_Ready-success)

---

## 1. Project Overview

This project implements a fully automated, end-to-end **Data Engineering Pipeline** that extracts recipe, user, and interaction data from **Google Firestore**, cleans and normalizes it, validates data quality, and generates analytics-ready insights and visualizations.

The pipeline simulates a real-world production data system with:

- NoSQL â†’ relational normalization  
- Data quality validation and quarantining  
- Automated orchestration via a single command  
- Insight generation with visual analytics  

**Seed Data:** Includes one custom, real recipe (user-provided) as the foundational dataset, along with synthetic supporting data.

---

## 2.Data Model Architecture

Firestore stores semi-structured JSON documents. During ETL, this data is normalized into a clean relational model.

### ğŸ”¹ Recipe Model

Each recipe contains:

- Unique ID  
- Title & description  
- Cuisine & difficulty  
- Prep/Cook/Total times  
- Ingredients (array of objects)  
- Steps (array of strings)  
- Metadata: created_by, timestamps  

Ingredients example:

```json
{
  "name": "Onion",
  "quantity": 2,
  "unit": "pcs"
}
```

Steps stored as an ordered list.

---

### ğŸ”¹ Users Model

User documents store:

- user_id  
- display name  
- age  
- food preferences  
- account creation timestamp  

---

### ğŸ”¹ Interactions Model

Captures user engagement:

- interaction_id  
- user_id  
- recipe_id  
- type: view / like / rating / attempt  
- rating (optional)  
- timestamp  

---

## Entity Relationship Diagram (ERD)

```mermaid
erDiagram
    USERS ||--o{ INTERACTIONS : performs
    RECIPES ||--o{ INTERACTIONS : receives
    RECIPES ||--o{ INGREDIENTS : contains
    RECIPES ||--o{ STEPS : includes

    USERS {
        string id PK
        string display_name
        string city
        string food_preferences
    }

    RECIPES {
        string id PK
        string title
        string cuisine
        string difficulty
        number prep_time_min
        number cook_time_min
        number total_time_min
        string tags
    }

    INGREDIENTS {
        string recipe_id FK
        string ingredient_name
        string quantity
        string unit
    }

    STEPS {
        string recipe_id FK
        number step_number
        string step_text
    }

    INTERACTIONS {
        string id PK
        string recipe_id FK
        string user_id FK
        string type
        string metadata_json
        timestamp timestamp
    }
```

---

## 3. Firebase Setup & Data Seeding

### Firestore Collections

- `recipes`
- `users`
- `interactions`

### Seeder Script Generates:

- 1 real recipe  
- 20 synthetic recipes  
- 10 synthetic users  
- 300â€“400 interactions  

This creates a realistic dataset for analytics.

---

## 4. ETL Pipeline Overview

### Pipeline Diagram

```mermaid
flowchart LR
    A[Firestore Source] --> B[Extract JSON]

    B --> C[Normalize via ETL]

    subgraph Transformation Logic
    C --> C1[Explode Arrays]
    C --> C2[Type Casting]
    C --> C3[Deduplication]
    C --> C4[Schema Enforcement]
    end

    C --> D[Validated CSV Outputs]
    C --> E[Quarantine Bad Data]
```

### Extraction

Firestore â†’ JSON:

```
export/
â”œâ”€â”€ recipes.json
â”œâ”€â”€ users.json
â””â”€â”€ interactions.json
```

### Transformation

ETL normalizes documents into:

```
output/etl/
â”œâ”€â”€ recipe.csv
â”œâ”€â”€ ingredients.csv
â”œâ”€â”€ steps.csv
â””â”€â”€ interactions.csv
```

### Quarantine System

Invalid records stored at:

```
output/bad_data/
```

---

## 5. Data Quality & Validation

Validation rules include:

| Rule Type | Description |
|----------|-------------|
| Completeness | Required fields must exist |
| Numeric Validity | Times must be â‰¥ 0 |
| Difficulty Domain | Only Easy / Medium / Hard |
| Referential Integrity | Valid recipe_id references |
| Structural Integrity | Steps & ingredients must be non-empty |
| Duplicate Detection | Duplicate IDs are quarantined |

Outputs:

```
output/validation/
â”œâ”€â”€ validation_report.md
â””â”€â”€ validation_results.json
```

---

## 6. Analytics & Insights

The analytics module (`analytics.py`) generates **15 strategic, consultant-grade visualizations** designed to reveal user behavior, recipe performance, operational risks, and business opportunities.

Charts cover **four strategic categories**:

---

### ğŸ§  Category 1 â€” User Psychology & Behavior

1. **Instagram Trap** â€” high views â‰  conversions  
2. **Step Fatigue** â€” drop-off after ~15 steps  
3. **30-Minute Cliff** â€” 2Ã— engagement for fast recipes  
4. **Effort vs Reward** â€” complexity vs rating  

---

### ğŸ’° Category 2 â€” Content Strategy & ROI

5. **ROI Landscape** â€” rating / minute  
6. **Skill Gap** â€” variance by difficulty  
7. **Cuisine Conversion Power**  
8. **Batch Cooking Demand**  

---

### ğŸ“¦ Category 3 â€” Supply Chain & Operations

9. **Critical Ingredients**  
10. **Ingredient Barrier**  
11. **Inventory Efficiency Risk**  

---

### ğŸš€ Category 4 â€” App Growth & Monetization

12. **Onboarding Heroes**  
13. **Viral Vectors**  
14. **Prep vs Cook Time Distribution**  
15. **Correlation Matrix**  

---

### ğŸ“„ Analytics Report Generation

A full report is auto-generated:

```
output/analytics/analytics_summary.md
```

Includes:

- Strategic insights  
- Chart explanations  
- Timestamped metadata  

---

### ğŸ“ Analytics Outputs

```
output/analytics/charts/
```

Examples:

```
1_instagram_trap.png
2_step_fatigue.png
5_roi_landscape.png
10_ingredient_barrier.png
15_correlation_matrix.png
```




## 7. Orchestration System

The entire workflow is automated using a single orchestrator:

```
python pipeline.py
```

Pipeline stages triggered:

1. Export Firestore  
2. ETL normalization  
3. Validation  
4. Analytics  

A complete manifest is stored:

```
output/logs/
```

This ensures reproducibility and traceabilityâ€”similar to real-world Airflow or Prefect workflows, but implemented in pure Python.

---

## 8. Setup & Execution Instructions

### Install Requirements

```
pip install -r requirements.txt
```

### Add Firebase Credentials

Place Firestore key:

```
serviceAccountKey.json
```

### Run Entire Pipeline

```
python pipeline.py
```

### View Outputs

```
output/
    â”œâ”€â”€ etl/
    â”œâ”€â”€ validation/
    â”œâ”€â”€ analytics/
    â””â”€â”€ bad_data/
```

---

## 9. Directory Structure

```
project/
â”œâ”€â”€ pipeline.py
â”œâ”€â”€ export/
â”œâ”€â”€ output/
â”‚   â”œâ”€â”€ etl/
â”‚   â”œâ”€â”€ analytics/
â”‚   â”œâ”€â”€ validation/
â”‚   â””â”€â”€ bad_data/
â”œâ”€â”€ serviceAccountKey.json
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## 10. Known Limitations

- Synthetic recipe data may not reflect real-world distributions.
- Pandas-based ETL is optimized for local scale.
- Firestore export is full-dump (not incremental).
- Orchestration is Python-based, not Airflow/Prefect.

---

## Final Statement

This project demonstrates a strong production-style data engineering workflow with:

- Automated orchestration  
- Reliable validation  
- Scalable transformation  
- Insightful analytics  

A complete end-to-end Firestore â†’ ETL â†’ Validation â†’ Analytics pipeline.

